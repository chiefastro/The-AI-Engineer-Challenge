# OpenAI Chat API Backend

This is a FastAPI-based backend service that provides a streaming chat interface using OpenAI's API and a Supabase-powered leaderboard system.

## Prerequisites

- Python 3.8 or higher
- uv (Python package installer)
- An OpenAI API key
- A Supabase account (free tier works great!)

## Setup

1. Create a virtual environment (recommended):
```bash
python -m venv venv
source venv/bin/activate  # On Windows, use: venv\Scripts\activate
```

2. Install the required dependencies using uv:
```bash
uv pip install -e .
```

3. Set up your environment variables:
```bash
# On Unix/Linux/MacOS
export OPENAI_API_KEY=your-api-key-here
export SUPABASE_URL=your-supabase-project-url
export SUPABASE_KEY=your-supabase-anon-key

# On Windows
set OPENAI_API_KEY=your-api-key-here
set SUPABASE_URL=your-supabase-project-url
set SUPABASE_KEY=your-supabase-anon-key
```

## Supabase Setup

1. Create a new project at [Supabase](https://supabase.com)
2. Once your project is ready, create the leaderboard table:
```sql
create table leaderboard (
  id bigint generated by default as identity primary key,
  initials text not null,
  score integer not null,
  created_at timestamptz not null
);
```

3. Create the leaderboard window function:
```sql
create or replace function get_leaderboard_window(
    p_initials text,
    p_score integer,
    p_window_size integer
)
returns table (
    initials text,
    score integer,
    created_at timestamptz,
    rank bigint
)
language plpgsql
security invoker
as $$
begin
    return query
    with ranked_scores as (
        select 
            l.initials,
            l.score,
            l.created_at,
            row_number() over (order by l.score desc) as rank
        from leaderboard l
    ),
    current_rank as (
        select rs.rank as current_rank
        from ranked_scores rs
        where rs.initials = p_initials and rs.score = p_score
    )
    select 
        rs.initials,
        rs.score,
        rs.created_at,
        rs.rank
    from ranked_scores rs
    cross join current_rank cr
    where rs.rank between cr.current_rank - p_window_size and cr.current_rank + p_window_size
    order by rs.rank asc;
end;
$$;

-- Grant necessary permissions
grant execute on function get_leaderboard_window(text, integer, integer) to anon;
grant execute on function get_leaderboard_window(text, integer, integer) to authenticated;
```

4. Get your project URL and anon key from the project settings and add them to your environment variables.

## Running the Server

1. Make sure you're in the `api` directory:
```bash
cd api
```

2. Start the server:
```bash
python app.py
```

The server will start on `http://localhost:8000`

## API Endpoints

### Chat Endpoint
- **URL**: `/api/chat`
- **Method**: POST
- **Request Body**:
```json
{
    "developer_message": "string",
    "user_message": "string",
    "model": "gpt-4.1-mini",  // optional
    "message_history": []  // optional
}
```
- **Response**: Streaming text response

### Leaderboard Endpoint
- **URL**: `/api/leaderboard`
- **Method**: POST
- **Request Body**:
```json
{
    "initials": "string",
    "score": number
}
```
- **Response**: Array of leaderboard entries with ranks

### Health Check
- **URL**: `/api/health`
- **Method**: GET
- **Response**: `{"status": "ok"}`

## API Documentation

Once the server is running, you can access the interactive API documentation at:
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## CORS Configuration

The API is configured to accept requests from any origin (`*`). This can be modified in the `app.py` file if you need to restrict access to specific domains.

## Error Handling

The API includes basic error handling for:
- Invalid API keys
- OpenAI API errors
- Database errors
- General server errors

All errors will return a 500 status code with an error message. 

## Vercel Deployment

When deploying to Vercel, you'll need to configure the environment variables:

1. Go to your project on [Vercel Dashboard](https://vercel.com)
2. Click on "Settings"
3. Click on "Environment Variables" in the left sidebar
4. Add these environment variables:
   - `OPENAI_API_KEY`: Your OpenAI API key
   - `SUPABASE_URL`: Your Supabase project URL
   - `SUPABASE_KEY`: Your Supabase anon key
   - Environment: Production (and optionally Preview/Development)
5. Click "Save"

Alternatively, you can use the Vercel CLI:
```bash
vercel env add OPENAI_API_KEY
vercel env add SUPABASE_URL
vercel env add SUPABASE_KEY
```

After adding the environment variables, redeploy your application for the changes to take effect. 